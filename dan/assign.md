
AdaGrad
==============

When you're doing gradient descent, some dimensions are more important than others.  We won't be doing vanilla SGD; instead, we'll focus on particular dimensions.  You should not need to modify the code to do this.

Autodifferentiation and GPUs
==============

I'm well aware that all of the cool kids are doing deep learning on GPUs and with deep learning toolkits.  However, using toolkits makes it harder to learn what's going on, and 
